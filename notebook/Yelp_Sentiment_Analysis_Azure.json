{
	"name": "Yelp_Sentiment_Analysis_Azure",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "594f2e8e-ec35-462d-b527-de2eebf3685f"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Yelp Business Reviews - Sentiment Analysis"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Importing Libraries"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import numpy as np\n",
					"import pandas as pd\n",
					"import seaborn as sns\n",
					"import matplotlib.pyplot as plt\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.functions import col, length, lit, lower, regexp_replace, size, split, filter, udf, sum, when\n",
					"from pyspark.sql.types import ArrayType,StringType, FloatType, StructType, StructField\n",
					"\n",
					"from pyspark.ml.feature import CountVectorizer\n",
					"from pyspark.ml.classification import LogisticRegression\n",
					"from pyspark.ml.linalg import Vector\n",
					"from pyspark.ml.functions import vector_to_array"
				],
				"execution_count": 237
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Creating Spark Environment"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true
					}
				},
				"source": [
					"# UNCOMMENT WHEN RUNNING LOCALLY \n",
					"\n",
					"\"\"\" \n",
					"# Create a spark session\n",
					"findspark.init()\n",
					"spark = SparkSession.builder \\\n",
					"    .appName(\"Yelp_Sentiment_Analysis\") \\\n",
					"    .master(\"local[8]\") \\\n",
					"    .config(\"spark.executor.memory\", \"10g\") \\\n",
					"    .config(\"spark.executor.cores\", \"3\") \\\n",
					"    .config(\"spark.driver.memory\", \"2g\") \\\n",
					"    .getOrCreate()\n",
					"\n",
					"### Patlarsa dene\n",
					"#.config(\"spark.memory.offHeap.enabled\",\"true\") \n",
					"#.config(\"spark.memory.offHeap.size\",\"10g\")\n",
					"\"\"\""
				],
				"execution_count": 238
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true
					}
				},
				"source": [
					"# Get config\n",
					"conf = spark.sparkContext.getConf()\n",
					"\n",
					"# Print the configuration settings\n",
					"print(\"spark.app.name = \", conf.get(\"spark.app.name\"))\n",
					"print(\"spark.master = \", conf.get(\"spark.master\"))\n",
					"print(\"spark.executor.memory = \", conf.get(\"spark.executor.memory\"))\n",
					"print(\"spark.executor.cores = \", conf.get(\"spark.executor.cores\")),\n",
					"print(\"spark.driver.memory = \", conf.get(\"spark.driver.memory\"))\n",
					"print(\"spark.rpc.message.maxSize = \", conf.get(\"spark.rpc.message.maxSize\"))\n",
					"print(\"spark.kryoserializer.buffer.max = \", conf.get(\"spark.kryoserializer.buffer.max\"))"
				],
				"execution_count": 239
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# UNCOMMENT WHEN RUNNING LOCALLY \r\n",
					"\r\n",
					"\"\"\"\r\n",
					"# Source file pathways on local disk\r\n",
					"path_business = \"../yelp_academic_dataset_business.json\"\r\n",
					"path_review = \"../yelp_academic_dataset_review.json\"\r\n",
					"positive_path = \"../positive_words.txt\"\r\n",
					"negative_path = \"../negative_words.txt\"\r\n",
					"\"\"\""
				],
				"execution_count": 241
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Source file pathways on ABFSS\r\n",
					"path_business = \"abfss://unity-catalog-storage@dbstoragepwtbcgut4qtn6.dfs.core.windows.net/yelp_academic_dataset_business.json\"\r\n",
					"path_review = \"abfss://unity-catalog-storage@dbstoragepwtbcgut4qtn6.dfs.core.windows.net/yelp_academic_dataset_review.json\"\r\n",
					"positive_path = \"abfss://unity-catalog-storage@dbstoragepwtbcgut4qtn6.dfs.core.windows.net/positive_words.txt\"\r\n",
					"negative_path = \"abfss://unity-catalog-storage@dbstoragepwtbcgut4qtn6.dfs.core.windows.net/negative_words.txt\""
				],
				"execution_count": 242
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Data Preprocessing"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### I. Cleaning of 'Business' Dataset"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Import business data\n",
					"business = spark.read.json(path_business)"
				],
				"execution_count": 243
			},
			{
				"cell_type": "code",
				"source": [
					"# Print first 10 rows\n",
					"business.show(n=10, truncate=10)"
				],
				"execution_count": 244
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Drop irrelevant columns\r\n",
					"business = business.drop('attributes','hours')"
				],
				"execution_count": 245
			},
			{
				"cell_type": "code",
				"source": [
					"# Print current dataset schema\n",
					"business.printSchema()"
				],
				"execution_count": 246
			},
			{
				"cell_type": "code",
				"source": [
					"# Filter out rows with null 'categories'\n",
					"business = business.filter(col(\"categories\").isNotNull())"
				],
				"execution_count": 247
			},
			{
				"cell_type": "code",
				"source": [
					"# Filter for businesses in US states\n",
					"states = [ \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\",\\\n",
					" \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", ]\n",
					" \n",
					"usa = business.filter(col(\"state\").isin(states))"
				],
				"execution_count": 248
			},
			{
				"cell_type": "code",
				"source": [
					"# Print out the total number of businesses in dataset\n",
					"print(f\"Number of US businesses in the dataset: {usa.count()}\")"
				],
				"execution_count": 249
			},
			{
				"cell_type": "code",
				"source": [
					"# Filter restaurants\n",
					"us_restaurants = usa.filter(usa[\"categories\"].contains(\"Restaurants\"))\n",
					"\n",
					"# Print out the number of total US restaurants\n",
					"print(f\"Number of total US restaurants in the dataset: {us_restaurants.count()}\")"
				],
				"execution_count": 250
			},
			{
				"cell_type": "code",
				"source": [
					"# Label every row with their type of cuisine\n",
					"us_restaurants = us_restaurants.withColumn(\n",
					"    \"category\",\n",
					"    when(col(\"categories\").contains(\"Korean\"), \"Korean\")\n",
					"    .when(col(\"categories\").contains(\"Thai\"), \"Thai\")\n",
					"    .when(col(\"categories\").contains(\"French\"), \"French\")\n",
					"    .when(col(\"categories\").contains(\"Greek\"), \"Greek\")\n",
					"    .when(col(\"categories\").contains(\"Indian\"), \"Indian\")\n",
					"    .when(col(\"categories\").contains(\"Hawaiian\"), \"Hawaiian\")\n",
					"    .when(col(\"categories\").contains(\"African\"), \"African\")\n",
					"    .when(col(\"categories\").contains(\"Spanish\"), \"Spanish\")\n",
					")"
				],
				"execution_count": 251
			},
			{
				"cell_type": "code",
				"source": [
					"# Drop the old category column\n",
					"us_restaurants = us_restaurants.drop(\"categories\")\n",
					"\n",
					"# Filter out null categories\n",
					"us_restaurants = us_restaurants.filter(col(\"category\").isNotNull())"
				],
				"execution_count": 252
			},
			{
				"cell_type": "code",
				"source": [
					"# Print out the total number of restaurants that are labeled by their cuisine types\n",
					"print(f\"Number of labeled US restaurants in the dataset: {us_restaurants.count()}\")"
				],
				"execution_count": 253
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Check if the dataset contains any duplicated businesses\n",
					"us_restaurants.groupBy(\"business_id\").count().filter(col(\"count\") > 1).count()"
				],
				"execution_count": 254
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show us_restaurants after cleaning\r\n",
					"us_restaurants.show(5)"
				],
				"execution_count": 255
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### II. Cleaning of 'Review' Dataset"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Import review data\n",
					"review = spark.read.json(path_review)"
				],
				"execution_count": 256
			},
			{
				"cell_type": "code",
				"source": [
					"# Print first 10 rows\n",
					"review.show(n=10, truncate=20)"
				],
				"execution_count": 257
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Select relevant columns\r\n",
					"review = review.select('business_id','text','stars')"
				],
				"execution_count": 258
			},
			{
				"cell_type": "code",
				"source": [
					"# Print current dataset schema\n",
					"review.printSchema()"
				],
				"execution_count": 259
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### III. Joining Datasets"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Change the names of 'stars' columns in both datasets to avoid confusion\n",
					"us_restaurants = us_restaurants.withColumnRenamed(\"stars\", \"avg_star\")\n",
					"review = review.withColumnRenamed(\"stars\", \"review_star\")"
				],
				"execution_count": 260
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Join the dataframes on 'business_id'\n",
					"restaurants_reviews = us_restaurants.join(review, on=\"business_id\", how=\"inner\")"
				],
				"execution_count": 261
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false,
					"scrolled": true
				},
				"source": [
					"# Print the schema of merged dataframe\n",
					"restaurants_reviews.printSchema()"
				],
				"execution_count": 262
			},
			{
				"cell_type": "markdown",
				"source": [
					"### IV. Feature Extraction"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Create a 'labels' column\n",
					"# 4-5 Stars --> Positive\n",
					"# 3 Stars --> Neutral\n",
					"# 1-2 Stars --> Negative\n",
					"\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\n",
					"    \"labels\",\n",
					"    when(restaurants_reviews[\"review_star\"] >= 4, \"positive\")\n",
					"    .when(restaurants_reviews[\"review_star\"] == 3, \"neutral\")\n",
					"    .when(restaurants_reviews[\"review_star\"] < 3, \"negative\"),\n",
					")"
				],
				"execution_count": 263
			},
			{
				"cell_type": "code",
				"source": [
					"# Filter out neutral reviews\n",
					"restaurants_reviews = restaurants_reviews.where(\n",
					"    restaurants_reviews[\"labels\"] != \"neutral\")\n",
					"\n",
					"# Count total number of positive and negative reviews\n",
					"\n",
					"print(f'The number of positive and negative reviews : {restaurants_reviews.count()}')"
				],
				"execution_count": 264
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert 'labels' column to boolean\r\n",
					"restaurants_reviews = restaurants_reviews.withColumn('labels_bool', when(col('labels') == 'positive' , 1).otherwise(0))"
				],
				"execution_count": 270
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show the distribution of reviews by category\r\n",
					"restaurants_reviews.groupBy('category').count().sort('count',ascending = False).show()"
				],
				"execution_count": 265
			},
			{
				"cell_type": "markdown",
				"source": [
					"### V. Text Processing"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Show 'text' column before processing\n",
					"restaurants_reviews.select(\"text\").show(10, truncate=80)"
				],
				"execution_count": 266
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### a. Text Cleaning"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Convert 'text' to lowercase\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\"text\", F.lower(F.col(\"text\")))"
				],
				"execution_count": 267
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Transform review text by using regular expressions\n",
					"\n",
					"# Replace all non-alphanumeric characters with a whitespace.\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\n",
					"    \"text_clean\", F.regexp_replace(F.col(\"text\"), \"[^a-zA-Z0-9\\s]\", \" \")\n",
					")\n",
					"\n",
					"# Replace all line break character with a whitespace.\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\n",
					"    \"text_clean\", F.regexp_replace(F.col(\"text_clean\"), \"\\n\", \" \")\n",
					")\n",
					"\n",
					"# Replace all consecutive whitespaces with a single whitespace.\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\n",
					"    \"text_clean\", F.regexp_replace(F.col(\"text_clean\"), \"\\\\s+\", \" \")\n",
					")\n",
					"\n",
					"# Delete all whitespace characters at the end of each string.\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\n",
					"    \"text_clean\", F.regexp_replace(F.col(\"text_clean\"), \"\\s+$\", \"\")\n",
					")"
				],
				"execution_count": 268
			},
			{
				"cell_type": "code",
				"source": [
					"# Show 'text_clean' column after transformation\n",
					"restaurants_reviews.select(\"text_clean\").show(10, truncate=50)"
				],
				"execution_count": 269
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### b. Stopword Removal"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"scrolled": true
				},
				"source": [
					"# There are 2 .txt files in the main directory where positive and negative words in English language are collected.\n",
					"# Mentioned text files will be used to evaluate whether a word is positive or negative.\n",
					"\n",
					"# Read text files and create RDDs\n",
					"positive_rdd = spark.sparkContext.textFile(positive_path)\n",
					"negative_rdd = spark.sparkContext.textFile(negative_path)\n",
					"\n",
					"# Convert RDDs into lists\n",
					"positive_words = positive_rdd.collect()\n",
					"negative_words = negative_rdd.collect()\n",
					"\n",
					"# Create lists with useless words that doesn't give any valuable info about restaurants.\n",
					"positive_useless = [ \"great\", \"amazing\", \"love\", \"best\", \"awesome\", \"excellent\", \"good\", \"favorite\", \"loved\", \"perfect\", \"gem\", \"perfectly\",\n",
					"\"wonderful\", \"happy\", \"enjoyed\", \"nice\", \"well\", \"super\", \"like\", \"better\", \"decent\", \"fine\", \"pretty\", \"enough\", \"excited\", \"impressed\", \n",
					"\"ready\", \"fantastic\", \"glad\", \"right\", \"fabulous\", ]\n",
					"negative_useless = [ \"bad\", \"disappointed\", \"unfortunately\", \"disappointing\", \"horrible\", \"lacking\", \"terrible\", \"sorry\", \"disappoint\", \"worst\", ]\n",
					"\n",
					"# Filter useless words out\n",
					"positive_words = [x for x in positive_words if x not in positive_useless]\n",
					"negative_words = [x for x in negative_words if x not in negative_useless]\n",
					"\n",
					"# Print first 10 elements of lists\n",
					"print(positive_words[:10])\n",
					"print(negative_words[:10])"
				],
				"execution_count": 272
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### c. Tokenization"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"def filter_words(col):\r\n",
					"    \"\"\" Splits text into a list of strings and filter out the words that are not in positive or negative word list.\"\"\"\r\n",
					"    \r\n",
					"    text = [i for i in col.split() if i in positive_words + negative_words]\r\n",
					"    return text"
				],
				"execution_count": 273
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a user-defined function (UDF) and filter text column\r\n",
					"restaurants_reviews = restaurants_reviews.withColumn(\"text_filtered\", udf(filter_words, returnType=ArrayType(StringType()))(col(\"text_clean\")))"
				],
				"execution_count": 274
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"#Drop unnecessary columns\r\n",
					"restaurants_reviews = restaurants_reviews.select(['category','text_filtered','labels_bool'])"
				],
				"execution_count": 276
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"#Print the schema\r\n",
					"restaurants_reviews.printSchema()"
				],
				"execution_count": 277
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Print the dataframe\r\n",
					"restaurants_reviews.show(3)"
				],
				"execution_count": 278
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Print the row number of dataframe\r\n",
					"restaurants_reviews.count()"
				],
				"execution_count": 281
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Implementing Bag-of-Words"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"After this point, all the processes will be implemented for 'African' restaurants."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Define a function that filters rows based on the 'category' parameter\n",
					"def get_dataset(category):\n",
					"    \"\"\"Takes in a category name as string. Returns a DataFrame with filtered rows based on category argument.\"\"\"\n",
					"\n",
					"    # Filter DataFrame to only include reviews for the given category\n",
					"    df = restaurants_reviews.filter(col(\"category\") == category)\n",
					"\n",
					"    # Select relevant columns\n",
					"    df = df.select([\"text_filtered\",\"labels_bool\"])\n",
					"\n",
					"    return df"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"source": [
					"# Get the dataframe for African restaurants\r\n",
					"African = get_dataset(\"African\")"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Display data types\r\n",
					"African.dtypes"
				],
				"execution_count": 311
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### I. Building Vocabulary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a CountVectorizer object\n",
					"vectorizer = CountVectorizer(inputCol = 'text_filtered', outputCol = 'vector')\n",
					"\n",
					"# Fit the CountVectorizer object to the dataset\n",
					"vectorizer_model = vectorizer.fit(African)"
				],
				"execution_count": 312
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Get word list learnt by 'vectorizer_model'\r\n",
					"vocab = vectorizer_model.vocabulary\r\n",
					"\r\n",
					"#Print out the first 10 element of the list\r\n",
					"vocab[:10]"
				],
				"execution_count": 27
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### II. Vectorization"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Transform the dataframe to get sparse vectors based on 'text_filtered' column\r\n",
					"African_df = vectorizer_model.transform(African)"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show the first 5 rows \r\n",
					"African_df.show(5,truncate = 80)"
				],
				"execution_count": 31
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### III. Deriving Weights"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a LogisticRegression object\r\n",
					"lr = LogisticRegression(featuresCol = 'vector', labelCol = 'labels_bool')\r\n",
					"\r\n",
					"# Fit the dataframe into object to create a LogisticRegressionModel object\r\n",
					"lr_model = lr.fit(African_df)"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Extract coefficients from LR model\r\n",
					"coeff = lr_model.coefficients\r\n",
					"\r\n",
					"# Convert coeficients to float dtype\r\n",
					"coeff = [float(i) for i in coeff]\r\n",
					"\r\n",
					"# Display first 10 elements\r\n",
					"coeff[:10]"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Zip the vocabulary and coefficient into a list of tuples\r\n",
					"word_coeff = [(i,j) for (i,j) in zip(vocab,coeff)]\r\n",
					"\r\n",
					"# Display the first 5 elements\r\n",
					"word_coeff[:5]"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a new dataframe contains vocabulary and their coefficients\r\n",
					"word_coeff_df = spark.createDataFrame(word_coeff,['word','coeff'])\r\n",
					"\r\n",
					"# Show the first 5 rows\r\n",
					"word_coeff_df.show(5)"
				],
				"execution_count": 33
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### IV. Creating the Bag-of-Words Matrix"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Select 'vector' column and display first 5 rows\r\n",
					"African_df.select('vector').show(5, truncate = 100)"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert sparse vector to dense array\r\n",
					"vector_dense_arr = vector_to_array(African_df.vector)\r\n",
					"\r\n",
					"# Add 'vector_dense' column to the dataframe\r\n",
					"African_df = African_df.withColumn('vector_dense',vector_dense_arr)"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show the first 5 rows\r\n",
					"African_df.show(5)"
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create an RDD from dataframe's 'vector_dense_arr' column\r\n",
					"vector_dense_rdd = African_df.select('vector_dense_arr').rdd\r\n",
					"\r\n",
					"# Convert RDD to list\r\n",
					"c = vector_dense_rdd.collect()\r\n",
					"\r\n",
					"# Print the type of 'c'\r\n",
					"type(c)"
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert c from a list of Row objects to a list of Float\r\n",
					"c = list(map(lambda x: x[0],c))"
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Define a StructType object to use as schema\r\n",
					"schema = StructType(\r\n",
					"[StructField(i,FloatType(),False) for i in vocab]\r\n",
					")\r\n",
					"\r\n",
					"# Print the first 10 elements of the schema\r\n",
					"schema[:10]"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a Spark Dataframe, using StructType as schema parameter\r\n",
					"matrix = spark.createDataFrame(c,schema = schema)"
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert Spark DataFrame to Pandas DataFrame\r\n",
					"matrix_pd = matrix.toPandas()\r\n",
					"\r\n",
					"# Show the first 3 rows\r\n",
					"matrix_pd.head(3)"
				],
				"execution_count": 43
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### V. Counting Frequencies"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Count the total number of occurrence for every word\r\n",
					"frequency = matrix_pd.sum(axis = 0)"
				],
				"execution_count": 44
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Print the pd series\r\n",
					"frequency"
				],
				"execution_count": 45
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert pd series to RDD\r\n",
					"freq_rdd = sc.parallelize(frequency)"
				],
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Convert RDD to list\r\n",
					"freq = freq_rdd.collect()"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Display first 10 elements of the list\r\n",
					"display(freq[:10])\r\n",
					"\r\n",
					"#Print the type of 'freq' variable\r\n",
					"type(freq)"
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Zip three variables and create a list of three tuples\r\n",
					"word_coeff_freq = [(i,j,k) for (i,j,k) in zip(vocab,coeff,freq)]"
				],
				"execution_count": 49
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Print the first 10 elements of the list\r\n",
					"word_coeff_freq[:10]"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create a Spark DataFrame from the list of tuples\r\n",
					"word_coeff_freq_df = spark.createDataFrame(word_coeff_freq, ['word','coeff','freq'])"
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show first 10 rows\r\n",
					"word_coeff_freq_df.show(10)"
				],
				"execution_count": 52
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### VI. Calculating Polarities"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Total number of reviews for the given category ('African', in this instance.)\r\n",
					"n = matrix.count()"
				],
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Polarity = (Coefficient * Frequency) / (Total number of reviews)\r\n",
					"# Calculate polarity and create new column\r\n",
					"African_master_df = word_coeff_freq_df.withColumn('polarity', col('coeff') * col('freq') / n)"
				],
				"execution_count": 54
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creating the Polarity Table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show the top 10 negative words\r\n",
					"African_master_df.sort('polarity',ascending = True).show(10)"
				],
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Show the top 10 positive words\r\n",
					"African_master_df.sort('polarity',ascending = False).show(10)"
				],
				"execution_count": 56
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Subset dataframes to get top and bottom 10 rows\r\n",
					"African_positive_10 = African_master_df.sort('polarity',ascending = False).head(10)\r\n",
					"African_negative_10 = African_master_df.sort('polarity',ascending = True).head(10)"
				],
				"execution_count": 60
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Creating pd DataFrames\r\n",
					"African_positive_10_pd = pd.DataFrame(African_positive_10, columns = African_master_df.columns)\r\n",
					"African_negative_10_pd = pd.DataFrame(African_negative_10, columns = African_master_df.columns)"
				],
				"execution_count": 153
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Sort negative words in descending order\r\n",
					"African_negative_10_pd = African_negative_10_pd.sort_values('polarity',ascending = False)"
				],
				"execution_count": 124
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Concatenate posiitve and negative words\r\n",
					"African_concat = pd.concat([African_positive_10_pd,African_negative_10_pd])\r\n",
					"\r\n",
					"# Print the polarity table\r\n",
					"African_concat.head(20)"
				],
				"execution_count": 125
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Generating the Plot"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Set 'darkgrid' style\r\n",
					"sns.set_style('darkgrid')\r\n",
					"# Set 'notebook' context for better readability\r\n",
					"sns.set_context('notebook')\r\n",
					"# Create a figure and an axis object of 9x6 size\r\n",
					"fig,ax = plt.subplots(figsize = (9,6))\r\n",
					"# Create a bar plot, 'polarity' on x axis and 'word' on y axis\r\n",
					"#Use a diverging palette for a better narrative impact\r\n",
					"sns.barplot(data = African_concat, x = 'polarity' , y = 'word', palette = 'RdBu_r')\r\n",
					"# Set the title of the plot\r\n",
					"plt.title(\"The Most Effective Words in African Restaurants's Reviews\")\r\n",
					"# Set labels for x and y axis.\r\n",
					"plt.xlabel('Polarity Score')\r\n",
					"plt.ylabel('Word')\r\n",
					"# Set the x-axis limits to the min and max values of the 'polarity' column\r\n",
					"plt.xlim(African_concat['polarity'].min(),African_concat['polarity'].max())\r\n",
					"# Show the plot\r\n",
					"plt.show()"
				],
				"execution_count": 152
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Function Definitions"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_polarity(category):\r\n",
					"    \"\"\"\r\n",
					"    Calculate polarity scores for a given category.\r\n",
					"\r\n",
					"    Args:\r\n",
					"    - category (str): Category of the restaurants to filter data.\r\n",
					"\r\n",
					"    Returns:\r\n",
					"    - DataFrame: DataFrame containing the top 10 positive and negative polarity words.\r\n",
					"    \"\"\"\r\n",
					"    \r\n",
					"    # Filter the df and get relevant columns\r\n",
					"    df = restaurants_reviews.filter(col(\"category\") == category)\r\n",
					"    df = df.select(['text_filtered','labels_bool'])\r\n",
					"\r\n",
					"    # Building vocabulary\r\n",
					"    vectorizer = CountVectorizer(inputCol = 'text_filtered', outputCol = 'vector')\r\n",
					"    vectorizer_model = vectorizer.fit(df)\r\n",
					"    vocab = vectorizer_model.vocabulary\r\n",
					"    \r\n",
					"    # Vectorization\r\n",
					"    df = vectorizer_model.transform()\r\n",
					"\r\n",
					"    # Deriving weights\r\n",
					"    lr = LogisticRegression(featuresCol = 'vector', labelCol = 'labels_bool')\r\n",
					"    lr_model = lr.fit(df)\r\n",
					"    coeff = lr_model.coefficients\r\n",
					"    coeff = [float(i) fo]\r\n",
					"    \r\n",
					"    # Creating the bag-of-words matrix\r\n",
					"    vector_dense_arr = vector_to_array(df.vector)\r\n",
					"    df = df.withColumn('vector_dense',vector_dense_arr)\r\n",
					"    vector_dense_rdd = df.select('vector_dense').rdd\r\n",
					"    vec = vector_dense_rdd.collect()\r\n",
					"    vec = list(map(lambda x: x[0],vec))\r\n",
					"    schema = StructType(\r\n",
					"    [StructField(i,FloatType(),False) for i in vocab]\r\n",
					"    )\r\n",
					"    matrix = spark.createDataFrame(vec,schema = schema)\r\n",
					"    matrix_pd = matrix.toPandas()\r\n",
					"    \r\n",
					"    # Counting frequencies\r\n",
					"    freq_series = matrix_pd.sum(axis = 0)\r\n",
					"    freq_rdd = sc.parallelize(freq_series)\r\n",
					"    freq = freq_rdd.collect()\r\n",
					"    word_coeff_freq = [(i,j,k) for (i,j,k) in zip(vocab,coeff,freq)]\r\n",
					"    word_coeff_freq_df = spark.createDataFrame(word_coeff_freq, ['word','coeff','freq'])\r\n",
					"    \r\n",
					"    # Calculating polarities\r\n",
					"    n = matrix.count()\r\n",
					"    master_df = word_coeff_freq_df.withColumn('polarity', col('coeff') * col('freq') / n)\r\n",
					"    \r\n",
					"    # Creating the polarity table\r\n",
					"    positive_10 = master_df.sort('polarity',ascending = False).head(10)\r\n",
					"    negative_10 = master_df.sort('polarity',ascending = True).head(10)\r\n",
					"    positive_10_pd = pd.DataFrame(positive_10, columns = master_df.columns)\r\n",
					"    negative_10_pd = pd.DataFrame(negative_10, columns = master_df.columns)\r\n",
					"    negative_10_pd = negative_10_pd.('polarity',ascending = False)\r\n",
					"    sum_df =positive_10_pd,negative_10_pd])\r\n",
					"    \r\n",
					"    # Return the df\r\n",
					"    return sum_df"
				],
				"execution_count": 282
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"def get_plot(sum_df,category):\r\n",
					"        \"\"\"\r\n",
					"    Generate a bar plot showing the most effective words in restaurant reviews for a given category.\r\n",
					"\r\n",
					"    Args:\r\n",
					"    - sum_df (DataFrame): DataFrame containing polarity scores and words.\r\n",
					"    - category (str): Category of the restaurants.\r\n",
					"    \"\"\"\r\n",
					"    # Set style and context\r\n",
					"    sns.set_style('darkgrid')\r\n",
					"    sns.set_context('notebook')\r\n",
					"\r\n",
					"    # Create a figure and axis object\r\n",
					"    fig,ax = plt.subplots(figsize = (9,6))\r\n",
					"\r\n",
					"    # Create the plot\r\n",
					"    sns.barplot(data = sum_df, x = 'polarity' , y = 'word',palette = 'RdBu_r')\r\n",
					"    \r\n",
					"    # Set the title and labels on both axis\r\n",
					"    plt.title(\"The Most Effective Words in \" + category + \" Restaurants's Reviews\")\r\n",
					"    plt.xlabel('Polarity Score')\r\n",
					"    plt.ylabel('Word')\r\n",
					"\r\n",
					"    # Set minimum and maximum limits on x-axis\r\n",
					"    plt.xlim(sum_df['polarity'].min(),sum_df['polarity'].max())\r\n",
					"\r\n",
					"    # Display the plot\r\n",
					"    plt.show()"
				],
				"execution_count": 283
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Implementation and Results"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"african_df = get_polarity('African')"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"african_df.head(20)"
				],
				"execution_count": 363
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(african_df,'African')"
				],
				"execution_count": 370
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"hawaiian_sum_df =get_polarity('Hawaiian')"
				],
				"execution_count": 371
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"hawaiian_sum_df.head(25)"
				],
				"execution_count": 373
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(hawaiian_sum_df,'Hawaiian')"
				],
				"execution_count": 372
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"spanish_sum_df = get_polarity('Spanish')"
				],
				"execution_count": 377
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"spanish_sum_df.head(25)"
				],
				"execution_count": 378
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(spanish_sum_df,'Spanish')"
				],
				"execution_count": 379
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"korean_sum_df = get_polarity('Korean')"
				],
				"execution_count": 98
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"korean_sum_df.head(25)"
				],
				"execution_count": 99
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(korean_sum_df, 'Korean')"
				],
				"execution_count": 100
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"greek_sum_df = get_polarity('Greek')"
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"greek_sum_df.head(25)"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(greek_sum_df, 'Greek')"
				],
				"execution_count": 103
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"indian_sum_df = get_polarity('Indian')"
				],
				"execution_count": 231
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"indian_sum_df.head(25)"
				],
				"execution_count": 232
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"get_plot(indian_sum_df, 'Indian')"
				],
				"execution_count": 233
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"french_sum_df = get_polarity('French')"
				],
				"execution_count": 284
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"french_sum_df.head(25)"
				],
				"execution_count": 285
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false,
					"scrolled": true
				},
				"source": [
					"get_plot(french_sum_df, 'French')"
				],
				"execution_count": 286
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"thai_sum_df = get_polarity('Thai')"
				],
				"execution_count": 287
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"thai_sum_df.head(25)"
				],
				"execution_count": 288
			},
			{
				"cell_type": "code",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"get_plot(thai_sum_df, 'Thai')"
				],
				"execution_count": 289
			}
		]
	}
}